package main

import ()

/*
hash table 中文可以称作哈希表
简单来说就是提供(key,value)的存取 当然只存key也是可以的
一般来说 哈希表的插入和查找的平均时间复杂度都是O(1)因此在日常工作中使用也较为广泛
1General Hash Table
实现
为了保证插入和查找的平均复杂度为O(1) hash table 底层一般都是使用数组来实现
对于给定的key 一般先进行hash操作 然后相对哈希表的长度取模 将key映射到指定的地方
index=hash(key) % hash_table_size //index就是key存储位置的索引
这里的核心在于如何选取合适的hash函数 如果提前知道key的一些相关信息 往往可以选取一个不错的hash函数
常用的hash函数有SHA-1 SHA-256 SHA-512,
冲突处理
冲突 也叫作碰撞 意思是两个或者多个key映射到了哈希表的同一个位置 冲突处理一般有两种方法
开放定址 open addressing 和开链 separate chaining
开放定址 的意思是当发生冲突时  我们从当前位置向后按某种策略遍历哈希表 当发现可用的空间的时候 则插入元素
开放地址有一次探测、二次探测和双重哈希。一次探测是指我们的遍历策略是一个线性函数，比如依次遍历冲突位置之后的第 1，2，3…N 位置。如果直接遍历 1，4（=2^2），9 (=3^2)，这就是二次探测的一个例子。双重哈希就是遍历策略间隔由另一个哈希函数来确定。
key “John Smith” 和 “Sandra Dee” 在 index = 152 位置出现冲突，使用开放地址的方法将 “Sandra Dee” 存放在 index = 153 的位置。之后 key “Ted Baker” 的映射位置为 index = 153，又出现冲突，则将其存放在 index = 154 的位置。由这个例子我们可以看出这种处理方法的一个缺点：解决旧问题的同时会引入新的问题。

开链的思想是哈希表中的每一个元素都是一个类似链表或者其他数据结构的head 当出现冲突时 我们就在链表后面
添加元素 这也就意味着 如果某一个位置冲突过多的话 插入的时间复杂度将退化为O(1)补充一点
如果哈希表的每个元素都是一个链表头的 那么又可以分为头存储元素和不存储元素两种
简单比较一下这两种处理方法的优劣：开放定址在解决当前冲突的情况下同时可能会导致新的冲突，而开链不会有这种问题。同时开链相比于开放定址局部性较差，在程序运行过程中可能引起操作系统的缺页中断，从而导致系统颠簸。

Rehash
很多语言或者工具包哈希表的内部实现都使用了两个数组 其中一个作为备用 如果当前哈希表的负载因子 元素个数/哈希表容量大小
过大或者过小时 就需要将数据切换到备用数组里面 这个过程就是rehash 新的哈希表的大小可以有很多种方案 比如redis里面的
哈希表 字典的底层实现 扩展时  新的哈希表的大小为 大于当前哈希表里面存放元素的2倍的最小的2的n次幂
Rehash过程也很有讲究 这个过程不应该影响当前系统的运行 所以比较推崇的一种方式是渐进式rehash 渐进式 rehash 的主要思想是在 rehash 阶段对于新的写请求，并不会写入老的哈希表里面，而是直接写入到新的哈希表里；对于读请求，优先读取新的哈希表，如果不存在，则去读老的的哈希表同时将这条数据迁移到新的哈希表里面来。

Rehash 有一个问题需要讨论一下：如何鉴定 rehash 阶段的开始与结束？开始很简单，每次写操作或者定期检测一下负载因子，当满足条件则开始 rehash。那么如何鉴定结束呢？一种比较常规的方法是定期检测，但是这涉及到很多问题，比如如何界定检测的时间粒度。另一种是记录下迁移过程。还是以 Redis 为例来说明，Redis 使用的是 1.2 介绍的哈希表元素作为链表头不存储元素的方式，这样数据迁移的时候只需要从原链表将节点删除，然后插入到新的哈希表对应的位置就好了。同时哈希表结构有一个字段记录了老的哈希表残留的数据，这样我们只需要检测这个变量（代价很小）就知道 rehash 有没有完成了

Bloom Filter
哈希表的问题在于空间利用率不够高 对于某些我们需要排重场景这个时候使用BloomFilter 中文又称作 布隆过滤器 就比较高级

Bloom filter的主要思想是使用位图 +多个哈希函数 省空间的常用方法就是使用位图 单个哈希函数 容易导致冲突
所以采用多个哈希函数 具体的方法是预先分配一个大数组作位图 对于每个key的写入 使用多个哈希函数映射到位图上的不同位置
对于key的查找 位图上的所有映射位置都为1时才表示key存在
var bitmap
func insert(key) {
    for h := range hashs {
        bitmap.setone(h(key))
    }
}

func lookup(key) bool {
    for h := range hashs {
        if bitmap.get(h(key)) != 1 {
            return false
        }
    }
    return true
}
上面只说到了插入和查找，那么删除呢？bloom filter 是不支持删除的。除此之后 bloom filter 对于不存在的 key 的查找是存在误判率的，但是这个概率对于大部分使用场景来说都是可接受的。关于误判率的具体推算可以参考其他资料，比如 wikipedia，这里就不细说了。

Bloom Filter 的最大缺点在于不支持删除操作。如果要实现删除操作的话则需要进行计数，这样就不满足空间效率高这一条初衷了。一种替代方案是使用 Cuckoo Filter，当然前提是也是可以容忍一定的误判率的。













*/
